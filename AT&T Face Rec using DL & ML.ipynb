{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285ffeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# used to supress display of warnings\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import random, copy, math, time\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7570ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress display of warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b0421",
   "metadata": {},
   "source": [
    "## Skip the code below and run the cells follwing the next heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8503f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "source_dir=r\"D:\\Users\\DELL\\Desktop\\Major Project\\AT&T Face Rec\\at&t_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebe7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "        self.base = base\n",
    "        # identity name\n",
    "        self.name = name\n",
    "        # image file name\n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        return os.path.join(self.base, self.name, self.file)\n",
    "\n",
    "def load_metadata(path):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path)[1:]:\n",
    "        for f in os.listdir(os.path.join(path, i)):\n",
    "            # Check file extension. Allow only jpg/jpeg' files.\n",
    "            ext = os.path.splitext(f)[1]\n",
    "            if ext == '.pgm':\n",
    "                metadata.append(IdentityMetadata(path, i, f))\n",
    "    return np.array(metadata)\n",
    "\n",
    "# metadata = load_metadata('images')\n",
    "metadata = load_metadata(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0d8b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata shape : (400,)\n"
     ]
    }
   ],
   "source": [
    "print('metadata shape :', metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b439f239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D:\\Users\\DELL\\Desktop\\Major Project\\AT&T Face Rec\\at&t_dataset\\s30\\5.pgm"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cdcef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.IdentityMetadata,\n",
       " 'D:\\\\Users\\\\DELL\\\\Desktop\\\\Major Project\\\\AT&T Face Rec\\\\at&t_dataset\\\\s23\\\\1.pgm')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metadata[150]), metadata[150].image_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87599fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af34b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = load_image('D:\\\\Users\\\\DELL\\\\Desktop\\\\Major Project\\\\AT&T Face Rec\\\\at&t_dataset\\\\s23\\\\1.pgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c18017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fc6b09e770>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575f95d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "vgg_face_embedder = load_model(r\"D:\\Users\\DELL\\Desktop\\Major Project\\Github Face Rec\\models-utilities\\vgg_face_embedder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ce2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros((metadata.shape[0], 2622))\n",
    "labels = []\n",
    "for i, m in enumerate(metadata):\n",
    "    img_path = metadata[i].image_path()\n",
    "    img = load_image(img_path)\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    img = cv2.resize(img, dsize = (224,224))\n",
    "    embedding_vector = vgg_face_embedder.predict(np.expand_dims(img, axis=0),verbose=0)[0]\n",
    "    embeddings[i]=embedding_vector\n",
    "    labels.append(metadata[i].name)\n",
    "    clear_output(wait=True)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad606c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"at&t_embds_400.pkl\",\"wb\") as f:\n",
    "    pickle.dump([metadata,embeddings],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3721f748",
   "metadata": {},
   "source": [
    "## Start From Here if not running for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17310c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce924b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"at&t_embds_400.pkl\",\"rb\") as f:\n",
    "    metadata_att, embeddings_att = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1140a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbbfeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b642e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embeddings_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7ef514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2622)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129691a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([m.name for m in metadata_att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc8a340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32bbb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2ad335",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aedc1564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s32    6\n",
       "s1     6\n",
       "s38    6\n",
       "s23    6\n",
       "s27    6\n",
       "s18    6\n",
       "s20    6\n",
       "s29    6\n",
       "s16    6\n",
       "s40    6\n",
       "s4     6\n",
       "s6     6\n",
       "s34    6\n",
       "s14    6\n",
       "s39    6\n",
       "s36    6\n",
       "s10    6\n",
       "s7     6\n",
       "s21    6\n",
       "s33    6\n",
       "s35    6\n",
       "s31    6\n",
       "s2     6\n",
       "s25    6\n",
       "s5     6\n",
       "s11    6\n",
       "s15    6\n",
       "s17    6\n",
       "s37    6\n",
       "s28    6\n",
       "s24    6\n",
       "s12    6\n",
       "s8     6\n",
       "s19    6\n",
       "s9     6\n",
       "s22    6\n",
       "s13    6\n",
       "s3     6\n",
       "s26    6\n",
       "s30    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9a6079a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "572b0754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d77becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49d5c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_std = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4c046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efe1324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s1' 's10' 's11' 's12' 's13' 's14' 's15' 's16' 's17' 's18' 's19' 's2'\n",
      " 's20' 's21' 's22' 's23' 's24' 's25' 's26' 's27' 's28' 's29' 's3' 's30'\n",
      " 's31' 's32' 's33' 's34' 's35' 's36' 's37' 's38' 's39' 's4' 's40' 's5'\n",
      " 's6' 's7' 's8' 's9']\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b54dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_encoded :  [25  0 17 35  2  6  8 30 20 11 16 38  6 10 39 16 35 14  4 22 11 39  2 20\n",
      " 18  3 24 28 17 26  4 20 17 31 24 10 20 26 38 15 19 31  9  9 31 12 12 21\n",
      "  7  3 19 21 10 30 34 33 36 27 39 34 27  8 22  5 32 12 29  1 14 27  5 19\n",
      "  8  1 26 22 31 27 36 21 22 34 39 37  3 22 37 24 29 34 10 38 34 13 18 12\n",
      "  6  5  3 37 24  4  0 18  5 18 16 36 17  1 35 13  8 28 23 19  5 12 15 28\n",
      " 13 39  8  0 10 38 16 14 36 15  0 35  5 35 18 27 33  1  6 33  0 37  4 32\n",
      " 24  3 15 26 37  8 38 22 21  7 11 10  6  2 23 11 16 33 14 29 13 24 33  7\n",
      " 21 25  2  9 35  9 19 21 17 19 30  4 25 25  6 29 15 27 23 32 38 26 12  7\n",
      " 23 29 11 23  2  1 23 28  9 31 20 14 11 32 26  1 13 15 37 16  4  7 39 30\n",
      "  3  0 32 20 30 31  7 13 17 32 25 36 18 28 14 28 29 30 34 36  2 25 33  9]\n",
      "y_test_encoded :  [ 2 11 34 15 21 36 19  8 13 25 27  3 19 12 28  4 26 38  7 32 14 23 31 25\n",
      " 39 32 39 14 39  7 17 27 12 33 20 14 16 18 34 33 30 23 11 18 10  7 36 24\n",
      " 22 26 37 15 30 35 27 19 17 27 13 10 10  1  3 31 35 37 10  7 24 16 15 17\n",
      " 16 35 31 20 11 31  1  0 37  8 29 24  3  4 24  0  0 33  2 36  8 38 21 29\n",
      "  9 18 22 13 28 19  9 20 34 12 34  9 16 26 20  6  4  8 23 33 25 15 18 32\n",
      "  2 11 35 37 21  5 26 23 22  1  6  9 32  5 39 28  3 38  6 29 38 14 21 22\n",
      "  1 36 25 30 29 28 12  4  6 13 17  5  5 30  2  0]\n"
     ]
    }
   ],
   "source": [
    "print('y_train_encoded : ', y_train_encoded)\n",
    "print('y_test_encoded : ', y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b23f6",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2f97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=128)\n",
    "x_train_pca = pca.fit_transform(x_train_std)\n",
    "x_test_pca = pca.transform(x_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a39df7",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8701d59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5.0, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5.0, gamma=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5.0, gamma=0.001)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_pca = SVC(C=5., gamma=0.001)\n",
    "clf_pca.fit(x_train_pca, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c7c93a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98125\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf_pca.predict(x_test_pca)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_encoded, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31830956",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba39a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 40)                2600      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241128 (941.91 KB)\n",
      "Trainable params: 241128 (941.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 4s 564ms/step - loss: 7.9230 - accuracy: 0.0111 - val_loss: 3.6788 - val_accuracy: 0.0667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 6.1635 - accuracy: 0.0278 - val_loss: 3.5291 - val_accuracy: 0.1167\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 5.1296 - accuracy: 0.0167 - val_loss: 3.5080 - val_accuracy: 0.1167\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 4.5333 - accuracy: 0.0222 - val_loss: 3.5105 - val_accuracy: 0.0667\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.3316 - accuracy: 0.0389 - val_loss: 3.5097 - val_accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.9277 - accuracy: 0.0444 - val_loss: 3.5014 - val_accuracy: 0.1500\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.9791 - accuracy: 0.0389 - val_loss: 3.4873 - val_accuracy: 0.2167\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7679 - accuracy: 0.0667 - val_loss: 3.4692 - val_accuracy: 0.2667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 3.7379 - accuracy: 0.1056 - val_loss: 3.4513 - val_accuracy: 0.2500\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.6205 - accuracy: 0.1278 - val_loss: 3.4333 - val_accuracy: 0.2667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.5303 - accuracy: 0.0944 - val_loss: 3.4143 - val_accuracy: 0.2833\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 3.4637 - accuracy: 0.1222 - val_loss: 3.3917 - val_accuracy: 0.2833\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 3.4306 - accuracy: 0.1111 - val_loss: 3.3683 - val_accuracy: 0.3500\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 3.5466 - accuracy: 0.0778 - val_loss: 3.3445 - val_accuracy: 0.3833\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.4413 - accuracy: 0.1056 - val_loss: 3.3195 - val_accuracy: 0.4333\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.3170 - accuracy: 0.0944 - val_loss: 3.2904 - val_accuracy: 0.4167\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.3311 - accuracy: 0.1833 - val_loss: 3.2570 - val_accuracy: 0.4333\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 3.2315 - accuracy: 0.1444 - val_loss: 3.2224 - val_accuracy: 0.4500\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 3.3640 - accuracy: 0.1278 - val_loss: 3.1871 - val_accuracy: 0.5167\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.0766 - accuracy: 0.2222 - val_loss: 3.1464 - val_accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.1147 - accuracy: 0.1556 - val_loss: 3.1015 - val_accuracy: 0.5167\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.1448 - accuracy: 0.1500 - val_loss: 3.0512 - val_accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.0410 - accuracy: 0.2167 - val_loss: 2.9951 - val_accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.9586 - accuracy: 0.2111 - val_loss: 2.9310 - val_accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.8681 - accuracy: 0.2611 - val_loss: 2.8631 - val_accuracy: 0.5833\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.8031 - accuracy: 0.2667 - val_loss: 2.7928 - val_accuracy: 0.6167\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.8081 - accuracy: 0.2278 - val_loss: 2.7208 - val_accuracy: 0.6333\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.6832 - accuracy: 0.3111 - val_loss: 2.6447 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.6112 - accuracy: 0.3167 - val_loss: 2.5649 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.6043 - accuracy: 0.2944 - val_loss: 2.4808 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.4294 - accuracy: 0.3111 - val_loss: 2.3955 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.4795 - accuracy: 0.3278 - val_loss: 2.3088 - val_accuracy: 0.7167\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.3918 - accuracy: 0.3444 - val_loss: 2.2202 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.2262 - accuracy: 0.4056 - val_loss: 2.1311 - val_accuracy: 0.7167\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.2183 - accuracy: 0.3889 - val_loss: 2.0428 - val_accuracy: 0.7167\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.1118 - accuracy: 0.4333 - val_loss: 1.9543 - val_accuracy: 0.7333\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.0254 - accuracy: 0.4556 - val_loss: 1.8633 - val_accuracy: 0.7333\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.0552 - accuracy: 0.4000 - val_loss: 1.7785 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.9144 - accuracy: 0.4833 - val_loss: 1.6929 - val_accuracy: 0.7833\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.7564 - accuracy: 0.4944 - val_loss: 1.6031 - val_accuracy: 0.7833\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 92ms/step - loss: 1.8633 - accuracy: 0.4833 - val_loss: 1.5117 - val_accuracy: 0.7833\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.8211 - accuracy: 0.5167 - val_loss: 1.4231 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.6278 - accuracy: 0.5278 - val_loss: 1.3441 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.4637 - accuracy: 0.6000 - val_loss: 1.2640 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.3955 - accuracy: 0.6167 - val_loss: 1.1847 - val_accuracy: 0.8167\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.4653 - accuracy: 0.5722 - val_loss: 1.1110 - val_accuracy: 0.8167\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.5222 - accuracy: 0.5889 - val_loss: 1.0453 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.4547 - accuracy: 0.6000 - val_loss: 0.9834 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.2286 - accuracy: 0.6389 - val_loss: 0.9246 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2672 - accuracy: 0.6611 - val_loss: 0.8778 - val_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.3254 - accuracy: 0.6111 - val_loss: 0.8361 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.2433 - accuracy: 0.6278 - val_loss: 0.7928 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0688 - accuracy: 0.6611 - val_loss: 0.7427 - val_accuracy: 0.8833\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.1666 - accuracy: 0.6389 - val_loss: 0.6952 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1455 - accuracy: 0.6833 - val_loss: 0.6526 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.1438 - accuracy: 0.6556 - val_loss: 0.6198 - val_accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.9513 - accuracy: 0.7444 - val_loss: 0.5897 - val_accuracy: 0.9333\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.9679 - accuracy: 0.7278 - val_loss: 0.5631 - val_accuracy: 0.9333\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.8009 - accuracy: 0.7778 - val_loss: 0.5363 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.9848 - accuracy: 0.7111 - val_loss: 0.5117 - val_accuracy: 0.9333\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.9805 - accuracy: 0.7000 - val_loss: 0.4860 - val_accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.7480 - accuracy: 0.7556 - val_loss: 0.4625 - val_accuracy: 0.9333\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.8409 - accuracy: 0.7333 - val_loss: 0.4395 - val_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6953 - accuracy: 0.8111 - val_loss: 0.4162 - val_accuracy: 0.9333\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.7025 - accuracy: 0.7722 - val_loss: 0.3924 - val_accuracy: 0.9333\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6761 - accuracy: 0.7667 - val_loss: 0.3719 - val_accuracy: 0.9333\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8375 - accuracy: 0.7833 - val_loss: 0.3529 - val_accuracy: 0.9333\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6795 - accuracy: 0.7889 - val_loss: 0.3348 - val_accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.7904 - accuracy: 0.7722 - val_loss: 0.3171 - val_accuracy: 0.9333\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4313 - accuracy: 0.8611 - val_loss: 0.2992 - val_accuracy: 0.9333\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.5055 - accuracy: 0.8667 - val_loss: 0.2835 - val_accuracy: 0.9500\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5732 - accuracy: 0.8111 - val_loss: 0.2689 - val_accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.7597 - accuracy: 0.7778 - val_loss: 0.2549 - val_accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5748 - accuracy: 0.8333 - val_loss: 0.2401 - val_accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4265 - accuracy: 0.8944 - val_loss: 0.2242 - val_accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4646 - accuracy: 0.8500 - val_loss: 0.2088 - val_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4966 - accuracy: 0.8500 - val_loss: 0.1942 - val_accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4702 - accuracy: 0.8389 - val_loss: 0.1778 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5112 - accuracy: 0.8278 - val_loss: 0.1641 - val_accuracy: 0.9833\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5714 - accuracy: 0.8611 - val_loss: 0.1529 - val_accuracy: 0.9833\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.3885 - accuracy: 0.8778 - val_loss: 0.1436 - val_accuracy: 0.9833\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5021 - accuracy: 0.8500 - val_loss: 0.1347 - val_accuracy: 0.9833\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5691 - accuracy: 0.8278 - val_loss: 0.1277 - val_accuracy: 0.9833\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5073 - accuracy: 0.8500 - val_loss: 0.1215 - val_accuracy: 0.9833\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4380 - accuracy: 0.8667 - val_loss: 0.1170 - val_accuracy: 0.9833\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4907 - accuracy: 0.8278 - val_loss: 0.1095 - val_accuracy: 0.9833\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4722 - accuracy: 0.8556 - val_loss: 0.1030 - val_accuracy: 0.9833\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3714 - accuracy: 0.8722 - val_loss: 0.0993 - val_accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3293 - accuracy: 0.9056 - val_loss: 0.0957 - val_accuracy: 0.9833\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3396 - accuracy: 0.9056 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.3808 - accuracy: 0.8944 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3050 - accuracy: 0.9111 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2596 - accuracy: 0.9222 - val_loss: 0.0811 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4160 - accuracy: 0.8778 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.3137 - accuracy: 0.8889 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3029 - accuracy: 0.9167 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2880 - accuracy: 0.9278 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.2588 - accuracy: 0.9111 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3074 - accuracy: 0.9222 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.3005 - accuracy: 0.9111 - val_loss: 0.0474 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_pca = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(128,)),\n",
    "    Dropout(0.50),  # Adding dropout for regularization\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.50),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.50),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(40, activation='softmax')  # Softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_pca.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model_pca.summary()\n",
    "\n",
    "# Train the model\n",
    "history_pca = model_pca.fit(x_train_pca, y_train_encoded, epochs=100, batch_size = 128, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2248219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "predictions = model_pca.predict(x_test_pca)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Test Accuracy:\",accuracy_score(y_test_encoded,predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae893a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_preds = model_pca.predict(x_train_pca)\n",
    "train_pred_classes = np.argmax(train_preds, axis=1)\n",
    "print(\"Train Accuracy:\",accuracy_score(y_train_encoded,train_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca2dc6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         4\n",
      "           8       1.00      1.00      1.00         4\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         4\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      1.00      1.00         4\n",
      "          24       1.00      1.00      1.00         4\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         4\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       1.00      1.00      1.00         4\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       1.00      1.00      1.00         4\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       1.00      1.00      1.00         4\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         4\n",
      "          38       1.00      1.00      1.00         4\n",
      "          39       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       160\n",
      "   macro avg       1.00      1.00      1.00       160\n",
      "weighted avg       1.00      1.00      1.00       160\n",
      " \n",
      "\n",
      "Classification Report:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test_encoded,predicted_classes)\n",
    "print(report,'\\n')\n",
    "report = classification_report(y_test_encoded,predicted_classes, output_dict=True)\n",
    "\n",
    "# Print aggregate metrics\n",
    "print(\"Classification Report:\")\n",
    "#print(report)\n",
    "print(\"Precision:\", report['macro avg']['precision'])\n",
    "print(\"Recall:\", report['macro avg']['recall'])\n",
    "print(\"F1-score:\", report['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d03afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca.save(\"att_dnn_model_pca.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2829b",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03baf9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=38)  # since n_components cannot be larger than min(num_features, num_classes-1)\n",
    "x_train_lda = lda.fit_transform(x_train_std, y_train_encoded)\n",
    "x_test_lda = lda.transform(x_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d4bc7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 38), (240,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lda.shape, y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922f765",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8b8223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5.0, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5.0, gamma=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5.0, gamma=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lda = SVC(C=5., gamma=0.001)\n",
    "clf_lda.fit(x_train_lda, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7049f75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf_lda.predict(x_test_lda)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_encoded, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d5cbd",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bac3a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 512)               19968     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 40)                2600      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195048 (761.91 KB)\n",
      "Trainable params: 195048 (761.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 470ms/step - loss: 6.3144 - accuracy: 0.0500 - val_loss: 3.5568 - val_accuracy: 0.0500\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.8752 - accuracy: 0.0222 - val_loss: 3.4798 - val_accuracy: 0.1167\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.4935 - accuracy: 0.0333 - val_loss: 3.4736 - val_accuracy: 0.2000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 4.1006 - accuracy: 0.0278 - val_loss: 3.4895 - val_accuracy: 0.2167\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.8317 - accuracy: 0.0333 - val_loss: 3.4828 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7136 - accuracy: 0.0556 - val_loss: 3.4551 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.6508 - accuracy: 0.0556 - val_loss: 3.4155 - val_accuracy: 0.3167\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.6496 - accuracy: 0.0833 - val_loss: 3.3790 - val_accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.5546 - accuracy: 0.1111 - val_loss: 3.3457 - val_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.5271 - accuracy: 0.0778 - val_loss: 3.3117 - val_accuracy: 0.3500\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.2728 - accuracy: 0.1444 - val_loss: 3.2767 - val_accuracy: 0.4333\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.2722 - accuracy: 0.1222 - val_loss: 3.2419 - val_accuracy: 0.4333\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.2301 - accuracy: 0.1833 - val_loss: 3.1970 - val_accuracy: 0.4500\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.2289 - accuracy: 0.1222 - val_loss: 3.1447 - val_accuracy: 0.4667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.2237 - accuracy: 0.1333 - val_loss: 3.0900 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.0777 - accuracy: 0.1833 - val_loss: 3.0305 - val_accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.1525 - accuracy: 0.1722 - val_loss: 2.9633 - val_accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 3.0495 - accuracy: 0.1944 - val_loss: 2.8859 - val_accuracy: 0.5667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.9496 - accuracy: 0.2056 - val_loss: 2.7978 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.7990 - accuracy: 0.2667 - val_loss: 2.7027 - val_accuracy: 0.6333\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.7245 - accuracy: 0.3167 - val_loss: 2.6070 - val_accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 2.7081 - accuracy: 0.2833 - val_loss: 2.5175 - val_accuracy: 0.7167\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.5788 - accuracy: 0.3333 - val_loss: 2.4246 - val_accuracy: 0.7667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.5450 - accuracy: 0.3222 - val_loss: 2.3286 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.3682 - accuracy: 0.3722 - val_loss: 2.2249 - val_accuracy: 0.8167\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.4002 - accuracy: 0.3556 - val_loss: 2.1077 - val_accuracy: 0.8167\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.3192 - accuracy: 0.4056 - val_loss: 1.9841 - val_accuracy: 0.8167\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2.1516 - accuracy: 0.5000 - val_loss: 1.8614 - val_accuracy: 0.8167\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.1592 - accuracy: 0.4167 - val_loss: 1.7382 - val_accuracy: 0.8167\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.0559 - accuracy: 0.4500 - val_loss: 1.6152 - val_accuracy: 0.8167\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.9612 - accuracy: 0.5222 - val_loss: 1.4986 - val_accuracy: 0.8500\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.7589 - accuracy: 0.5278 - val_loss: 1.3887 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.7776 - accuracy: 0.5056 - val_loss: 1.2865 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.8106 - accuracy: 0.4833 - val_loss: 1.1852 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.4675 - accuracy: 0.6500 - val_loss: 1.0906 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.5121 - accuracy: 0.5889 - val_loss: 1.0060 - val_accuracy: 0.9000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.4513 - accuracy: 0.6111 - val_loss: 0.9300 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.4325 - accuracy: 0.6111 - val_loss: 0.8611 - val_accuracy: 0.8833\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.3602 - accuracy: 0.6056 - val_loss: 0.7957 - val_accuracy: 0.8833\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2874 - accuracy: 0.6278 - val_loss: 0.7318 - val_accuracy: 0.8833\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.0861 - accuracy: 0.7222 - val_loss: 0.6671 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.9320 - accuracy: 0.7667 - val_loss: 0.6039 - val_accuracy: 0.9167\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.1732 - accuracy: 0.6833 - val_loss: 0.5434 - val_accuracy: 0.9833\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.9206 - accuracy: 0.7389 - val_loss: 0.4842 - val_accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.0403 - accuracy: 0.7389 - val_loss: 0.4304 - val_accuracy: 0.9833\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.8799 - accuracy: 0.7667 - val_loss: 0.3802 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.8955 - accuracy: 0.7333 - val_loss: 0.3364 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 95ms/step - loss: 0.8344 - accuracy: 0.7667 - val_loss: 0.2935 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7620 - accuracy: 0.7667 - val_loss: 0.2565 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.7296 - accuracy: 0.7944 - val_loss: 0.2262 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6428 - accuracy: 0.8444 - val_loss: 0.2000 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.9182 - accuracy: 0.7500 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6287 - accuracy: 0.8111 - val_loss: 0.1555 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.7067 - accuracy: 0.7944 - val_loss: 0.1385 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5863 - accuracy: 0.8500 - val_loss: 0.1263 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5549 - accuracy: 0.8111 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5801 - accuracy: 0.8222 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4805 - accuracy: 0.8611 - val_loss: 0.0957 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4825 - accuracy: 0.9000 - val_loss: 0.0870 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.4053 - accuracy: 0.8889 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4575 - accuracy: 0.8500 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5379 - accuracy: 0.8500 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5365 - accuracy: 0.8278 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5311 - accuracy: 0.8722 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5452 - accuracy: 0.8500 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4385 - accuracy: 0.8556 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3479 - accuracy: 0.9222 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4032 - accuracy: 0.8833 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.3645 - accuracy: 0.9111 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4043 - accuracy: 0.8778 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4004 - accuracy: 0.8833 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2933 - accuracy: 0.8889 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3626 - accuracy: 0.8944 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3046 - accuracy: 0.9111 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3345 - accuracy: 0.9056 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.3222 - accuracy: 0.9111 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2972 - accuracy: 0.9056 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3288 - accuracy: 0.8944 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3049 - accuracy: 0.9056 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3180 - accuracy: 0.9000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.2711 - accuracy: 0.9333 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3351 - accuracy: 0.9056 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2069 - accuracy: 0.9278 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2446 - accuracy: 0.9000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3473 - accuracy: 0.9056 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.2811 - accuracy: 0.9056 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3319 - accuracy: 0.9056 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.3077 - accuracy: 0.8944 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1762 - accuracy: 0.9389 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2695 - accuracy: 0.9056 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2121 - accuracy: 0.9333 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1679 - accuracy: 0.9444 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.2901 - accuracy: 0.9111 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.1906 - accuracy: 0.9389 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2256 - accuracy: 0.9278 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1891 - accuracy: 0.9333 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.2253 - accuracy: 0.9278 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2187 - accuracy: 0.9333 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.1759 - accuracy: 0.9389 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2069 - accuracy: 0.9500 - val_loss: 0.0011 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_lda = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(38,)),\n",
    "    Dropout(0.50),  # Adding dropout for regularization\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.50),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.50),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(40, activation='softmax')  # Softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_lda.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model_lda.summary()\n",
    "\n",
    "# Train the model\n",
    "history_lda = model_lda.fit(x_train_lda, y_train_encoded, epochs=100, batch_size = 128, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2002811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n",
      "Test Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "predictions = model_lda.predict(x_test_lda)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test_encoded,predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a4a53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "Train Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "train_preds = model_lda.predict(x_train_lda)\n",
    "train_pred_classes = np.argmax(train_preds, axis=1)\n",
    "print(\"Train Accuracy\", accuracy_score(y_train_encoded,train_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92f79baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         4\n",
      "           8       1.00      1.00      1.00         4\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         4\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      1.00      1.00         4\n",
      "          24       1.00      1.00      1.00         4\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         4\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       1.00      1.00      1.00         4\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       1.00      1.00      1.00         4\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       1.00      1.00      1.00         4\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         4\n",
      "          38       1.00      1.00      1.00         4\n",
      "          39       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       160\n",
      "   macro avg       1.00      1.00      1.00       160\n",
      "weighted avg       1.00      1.00      1.00       160\n",
      " \n",
      "\n",
      "Classification Report:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test_encoded,predicted_classes)\n",
    "print(report,'\\n')\n",
    "report = classification_report(y_test_encoded,predicted_classes, output_dict=True)\n",
    "\n",
    "# Print aggregate metrics\n",
    "print(\"Classification Report:\")\n",
    "#print(report)\n",
    "print(\"Precision:\", report['macro avg']['precision'])\n",
    "print(\"Recall:\", report['macro avg']['recall'])\n",
    "print(\"F1-score:\", report['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "191d0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lda.save(\"att_dnn_model_lda.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a702e",
   "metadata": {},
   "source": [
    "# PCA + LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36b970af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lda = LinearDiscriminantAnalysis(n_components=38)  # since n_components cannot be larger than min(num_features, num_classes-1)\n",
    "x_train_pca_lda = pca_lda.fit_transform(x_train_pca, y_train_encoded)\n",
    "x_test_pca_lda = pca_lda.transform(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7048e4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 38), (240,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pca_lda.shape, y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da69130",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1116aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5.0, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5.0, gamma=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5.0, gamma=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pca_lda = SVC(C=5., gamma=0.001)\n",
    "clf_pca_lda.fit(x_train_pca_lda, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2477a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf_pca_lda.predict(x_test_pca_lda)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_encoded, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c68e6",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33e6a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               19968     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 40)                2600      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195048 (761.91 KB)\n",
      "Trainable params: 195048 (761.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 438ms/step - loss: 11.3565 - accuracy: 0.0444 - val_loss: 4.1679 - val_accuracy: 0.0500\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 9.0824 - accuracy: 0.0333 - val_loss: 3.7519 - val_accuracy: 0.0667\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 7.3725 - accuracy: 0.0222 - val_loss: 3.5128 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.3791 - accuracy: 0.0444 - val_loss: 3.4037 - val_accuracy: 0.1333\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 5.1119 - accuracy: 0.0556 - val_loss: 3.3451 - val_accuracy: 0.1500\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 4.9086 - accuracy: 0.0778 - val_loss: 3.3015 - val_accuracy: 0.2000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.6704 - accuracy: 0.0556 - val_loss: 3.2808 - val_accuracy: 0.2667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 4.5632 - accuracy: 0.0500 - val_loss: 3.2638 - val_accuracy: 0.3167\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.9305 - accuracy: 0.1000 - val_loss: 3.2526 - val_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.8033 - accuracy: 0.1167 - val_loss: 3.2426 - val_accuracy: 0.3333\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.9008 - accuracy: 0.0889 - val_loss: 3.2301 - val_accuracy: 0.3667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.6930 - accuracy: 0.1056 - val_loss: 3.2118 - val_accuracy: 0.4333\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.6189 - accuracy: 0.1333 - val_loss: 3.1927 - val_accuracy: 0.4500\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.4770 - accuracy: 0.1556 - val_loss: 3.1777 - val_accuracy: 0.4333\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.5064 - accuracy: 0.1056 - val_loss: 3.1595 - val_accuracy: 0.4500\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.4233 - accuracy: 0.1611 - val_loss: 3.1310 - val_accuracy: 0.4833\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.2345 - accuracy: 0.1222 - val_loss: 3.1020 - val_accuracy: 0.5500\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.1288 - accuracy: 0.1778 - val_loss: 3.0703 - val_accuracy: 0.5667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.1789 - accuracy: 0.1556 - val_loss: 3.0372 - val_accuracy: 0.5833\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.0529 - accuracy: 0.2167 - val_loss: 2.9990 - val_accuracy: 0.6000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.2367 - accuracy: 0.1556 - val_loss: 2.9567 - val_accuracy: 0.6000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 2.9208 - accuracy: 0.2389 - val_loss: 2.9072 - val_accuracy: 0.6333\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.1187 - accuracy: 0.1667 - val_loss: 2.8586 - val_accuracy: 0.6333\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.0021 - accuracy: 0.2167 - val_loss: 2.8094 - val_accuracy: 0.6167\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.9267 - accuracy: 0.2278 - val_loss: 2.7578 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.9568 - accuracy: 0.2389 - val_loss: 2.7016 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.8625 - accuracy: 0.2167 - val_loss: 2.6373 - val_accuracy: 0.6500\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 2.7911 - accuracy: 0.2333 - val_loss: 2.5649 - val_accuracy: 0.6500\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.8176 - accuracy: 0.2667 - val_loss: 2.4894 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2.6938 - accuracy: 0.2778 - val_loss: 2.4206 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2.4481 - accuracy: 0.3500 - val_loss: 2.3442 - val_accuracy: 0.6833\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.5584 - accuracy: 0.2667 - val_loss: 2.2617 - val_accuracy: 0.7167\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 2.6131 - accuracy: 0.2611 - val_loss: 2.1817 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.4118 - accuracy: 0.3722 - val_loss: 2.1042 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2.1927 - accuracy: 0.3778 - val_loss: 2.0248 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.2394 - accuracy: 0.4111 - val_loss: 1.9434 - val_accuracy: 0.7833\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.0856 - accuracy: 0.4389 - val_loss: 1.8630 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.1500 - accuracy: 0.4500 - val_loss: 1.7884 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.2369 - accuracy: 0.4056 - val_loss: 1.7123 - val_accuracy: 0.8167\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.9769 - accuracy: 0.4556 - val_loss: 1.6391 - val_accuracy: 0.8167\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.9685 - accuracy: 0.4889 - val_loss: 1.5669 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.8617 - accuracy: 0.4667 - val_loss: 1.5004 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.8903 - accuracy: 0.4278 - val_loss: 1.4364 - val_accuracy: 0.8833\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.8003 - accuracy: 0.5056 - val_loss: 1.3705 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.7365 - accuracy: 0.5333 - val_loss: 1.3058 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.6087 - accuracy: 0.5556 - val_loss: 1.2360 - val_accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.5376 - accuracy: 0.5833 - val_loss: 1.1672 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4303 - accuracy: 0.6111 - val_loss: 1.1012 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.5569 - accuracy: 0.5667 - val_loss: 1.0400 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.4897 - accuracy: 0.5667 - val_loss: 0.9829 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4377 - accuracy: 0.6111 - val_loss: 0.9324 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4306 - accuracy: 0.6167 - val_loss: 0.8799 - val_accuracy: 0.9667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.2163 - accuracy: 0.6333 - val_loss: 0.8279 - val_accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.3267 - accuracy: 0.6278 - val_loss: 0.7769 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2519 - accuracy: 0.6611 - val_loss: 0.7217 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.2631 - accuracy: 0.5944 - val_loss: 0.6641 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1618 - accuracy: 0.6722 - val_loss: 0.6078 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.0360 - accuracy: 0.6944 - val_loss: 0.5582 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.0196 - accuracy: 0.7000 - val_loss: 0.5115 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.1114 - accuracy: 0.6667 - val_loss: 0.4667 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.9593 - accuracy: 0.7167 - val_loss: 0.4212 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.8504 - accuracy: 0.7722 - val_loss: 0.3755 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.8980 - accuracy: 0.7389 - val_loss: 0.3331 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9288 - accuracy: 0.7333 - val_loss: 0.2956 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.9199 - accuracy: 0.7389 - val_loss: 0.2643 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.9449 - accuracy: 0.7278 - val_loss: 0.2355 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.8374 - accuracy: 0.7333 - val_loss: 0.2125 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.7371 - accuracy: 0.7778 - val_loss: 0.1921 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7957 - accuracy: 0.7778 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8532 - accuracy: 0.7944 - val_loss: 0.1576 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.7479 - accuracy: 0.7833 - val_loss: 0.1422 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6623 - accuracy: 0.7833 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.8072 - accuracy: 0.7556 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6446 - accuracy: 0.8222 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.7332 - accuracy: 0.7611 - val_loss: 0.0963 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.7420 - accuracy: 0.8167 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.8074 - accuracy: 0.7500 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6512 - accuracy: 0.8000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7037 - accuracy: 0.7944 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6793 - accuracy: 0.7944 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4679 - accuracy: 0.8500 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5790 - accuracy: 0.8389 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4712 - accuracy: 0.8611 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5595 - accuracy: 0.7944 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5104 - accuracy: 0.8444 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4892 - accuracy: 0.8444 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4525 - accuracy: 0.8444 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5092 - accuracy: 0.8444 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5027 - accuracy: 0.8333 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.4927 - accuracy: 0.8722 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4076 - accuracy: 0.8722 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5235 - accuracy: 0.8444 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5205 - accuracy: 0.8389 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4465 - accuracy: 0.8444 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4365 - accuracy: 0.8722 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3820 - accuracy: 0.8778 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3834 - accuracy: 0.8778 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3704 - accuracy: 0.9111 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.3657 - accuracy: 0.8778 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6074 - accuracy: 0.8389 - val_loss: 0.0111 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_pca_lda = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(38,)),\n",
    "    Dropout(0.50),  # Adding dropout for regularization\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.50),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.50),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(40, activation='softmax')  # Softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_pca_lda.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model_pca_lda.summary()\n",
    "\n",
    "# Train the model\n",
    "history_pca_lda = model_pca_lda.fit(x_train_pca_lda, y_train_encoded, epochs=100, batch_size = 128, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ec1dd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n",
      "Test Accuracy:  0.99375\n"
     ]
    }
   ],
   "source": [
    "predictions = model_pca_lda.predict(x_test_pca_lda)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test_encoded,predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "330f12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "Train Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "train_preds = model_pca_lda.predict(x_train_pca_lda)\n",
    "train_pred_classes = np.argmax(train_preds, axis=1)\n",
    "print(\"Train Accuracy\", accuracy_score(y_train_encoded,train_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8667fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         4\n",
      "           8       1.00      1.00      1.00         4\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         4\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00         4\n",
      "          15       1.00      1.00      1.00         4\n",
      "          16       1.00      1.00      1.00         4\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       1.00      0.75      0.86         4\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         4\n",
      "          23       1.00      1.00      1.00         4\n",
      "          24       1.00      1.00      1.00         4\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         4\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         4\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       1.00      1.00      1.00         4\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       1.00      1.00      1.00         4\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       1.00      1.00      1.00         4\n",
      "          35       1.00      1.00      1.00         4\n",
      "          36       1.00      1.00      1.00         4\n",
      "          37       1.00      1.00      1.00         4\n",
      "          38       1.00      1.00      1.00         4\n",
      "          39       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      " \n",
      "\n",
      "Classification Report:\n",
      "Precision: 0.9949999999999999\n",
      "Recall: 0.99375\n",
      "F1-score: 0.9936507936507937\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test_encoded,predicted_classes)\n",
    "print(report,'\\n')\n",
    "report = classification_report(y_test_encoded,predicted_classes, output_dict=True)\n",
    "\n",
    "# Print aggregate metrics\n",
    "print(\"Classification Report:\")\n",
    "#print(report)\n",
    "print(\"Precision:\", report['macro avg']['precision'])\n",
    "print(\"Recall:\", report['macro avg']['recall'])\n",
    "print(\"F1-score:\", report['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb4b7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lda.save(\"att_dnn_model_pca_lda.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cc04e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "embedder = load_model(r\"D:\\Users\\DELL\\Desktop\\Major Project\\Github Face Rec\\models-utilities\\vgg_face_embedder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03dba0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify(img_path, model, model_category, method):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        inp_img = cv2.imread(rf\"{img_path}\")\n",
    "        gray=cv2.cvtColor(inp_img, cv2.COLOR_BGR2GRAY)\n",
    "        inp_faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        new_img = copy.deepcopy(inp_img)\n",
    "        if len(inp_faces)==0:\n",
    "            input_face_region = inp_img\n",
    "            img = (input_face_region / 255.).astype(np.float32)\n",
    "            img = cv2.resize(img, dsize = (224,224))\n",
    "            embedding_vector = embedder.predict(np.expand_dims(img, axis=0),verbose=0)[0]\n",
    "            embv_scaled = scaler.transform([embedding_vector])\n",
    "            if method == 'pca':\n",
    "                final_inp = pca.transform(embv_scaled)\n",
    "            elif method == 'lda':\n",
    "                final_inp = lda.transform(embv_scaled)\n",
    "            elif method == 'pca_lda':\n",
    "                final_inp = pca.transform(embv_scaled)\n",
    "                final_inp = pca_lda.transform(final_inp)\n",
    "            if model_category == 'svm':\n",
    "                name = le.inverse_transform([model.predict(final_inp)])[0]\n",
    "                max_probab = 0.5\n",
    "            elif model_category == 'dnn':\n",
    "                probabs = model.predict(final_inp,verbose=0)\n",
    "                max_probab = np.max(probabs)\n",
    "                name = le.inverse_transform([np.argmax(probabs)])[0]\n",
    "        else:\n",
    "            for (x, y, w, h) in inp_faces:\n",
    "                input_face_region = inp_img[y:y+h, x:x+w]\n",
    "                img = (input_face_region / 255.).astype(np.float32)\n",
    "                img = cv2.resize(img, dsize = (224,224))\n",
    "                embedding_vector = embedder.predict(np.expand_dims(img, axis=0),verbose=0)[0]\n",
    "                embv_scaled = scaler.transform([embedding_vector])\n",
    "                if method == 'pca':\n",
    "                    final_inp = pca.transform(embv_scaled)\n",
    "                elif method == 'lda':\n",
    "                    final_inp = lda.transform(embv_scaled)\n",
    "                elif method == 'pca_lda':\n",
    "                    final_inp = pca.transform(embv_scaled)\n",
    "                    final_inp = pca_lda.transform(final_inp)\n",
    "                if model_category == 'svm':\n",
    "                    name = le.inverse_transform([model.predict(final_inp)])[0]\n",
    "                    max_probab = 0.5\n",
    "                elif model_category == 'dnn':\n",
    "                    probabs = model.predict(final_inp,verbose=0)\n",
    "                    max_probab = np.max(probabs)\n",
    "                    name = le.inverse_transform([np.argmax(probabs)])[0]\n",
    "                cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                new_img = cv2.putText(new_img,name,(x,y-10),cv2.FONT_HERSHEY_PLAIN,1,(255,0,255),2,cv2.LINE_4)\n",
    "            new_img = new_img[...,::-1]\n",
    "            #plt.figure(figsize=(30,30))\n",
    "    #        plt.imshow(new_img)\n",
    "        return name, max_probab\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9170c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(source_dir, model, model_category, method):\n",
    "    path = r\"D:\\Users\\DELL\\Desktop\\Major Project\\AT&T Face Rec\\at&t_dataset\"\n",
    "    not_reco_img = {}\n",
    "    mis_class = {}\n",
    "    ct = 0\n",
    "    min_probab = 1\n",
    "    for i in os.listdir(path)[1:]:\n",
    "        path_1 = os.path.join(path, i)\n",
    "        for f in os.listdir(path_1):\n",
    "            path_2 = os.path.join(path_1, f)\n",
    "            name, max_probab = identify(path_2, model, model_category, method)\n",
    "            if max_probab < min_probab:\n",
    "                min_probab = max_probab\n",
    "            ct += 1\n",
    "            if name == \"not recognized\":\n",
    "                if i in not_reco_img.keys():\n",
    "                    not_reco_img[i].append(f)\n",
    "                else:\n",
    "                    not_reco_img[i] = [f]\n",
    "            elif name != i:\n",
    "                if i in mis_class.keys():\n",
    "                    if name in mis_class[i].keys():\n",
    "                        mis_class[i][name] += 1\n",
    "                    else:\n",
    "                        mis_class[i][name] = 1\n",
    "                else:\n",
    "                    mis_class[i] = {}\n",
    "                    mis_class[i][name] = 1\n",
    "            else:\n",
    "                clear_output(wait=True)\n",
    "                print(model_category,method,\"\\n\")\n",
    "                print(\"Progress:\",ct,\"\\n\")\n",
    "                print(\"Not recognized images count:\")\n",
    "                print(not_reco_img,\"\\n\")\n",
    "                print(\"Misclassified images count:\")\n",
    "                print(mis_class,\"\\n\")\n",
    "                print(\"Most minimum probability for correct classification\",min_probab)\n",
    "    \n",
    "    return not_reco_img, mis_class, min_probab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adceae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = r\"D:\\Users\\DELL\\Desktop\\Major Project\\AT&T Face Rec\\at&t_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "896beedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'svm_pca' : {},\n",
    "    'svm_lda' : {},\n",
    "    'svm_pca_lda': {},\n",
    "    'dnn_pca' : {},\n",
    "    'dnn_lda' : {},\n",
    "    'dnn_pca_lda':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b8a6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = {\n",
    "    'svm_pca' : clf_pca,\n",
    "    'svm_lda' : clf_lda,\n",
    "    'svm_pca_lda': clf_pca_lda,\n",
    "    'dnn_pca' : model_pca,\n",
    "    'dnn_lda' : model_lda,\n",
    "    'dnn_pca_lda':model_pca_lda\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50692fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn pca_lda \n",
      "\n",
      "Progress: 400 \n",
      "\n",
      "Not recognized images count:\n",
      "{} \n",
      "\n",
      "Misclassified images count:\n",
      "{'s18': {'s40': 1}, 's26': {'s1': 1}, 's4': {'s27': 1}} \n",
      "\n",
      "Most minimum probability for correct classification 0.1431551\n"
     ]
    }
   ],
   "source": [
    "for key, model in model_dir.items():\n",
    "    if key in results.keys():\n",
    "        results[key]['not_reco_imgs'], results[key]['mis_classes'], results[key]['min_probabs'] =  test(source_dir, model, key[:3], key[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00af02a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm_pca': {'not_reco_imgs': {},\n",
       "  'mis_classes': {'s10': {'s20': 5},\n",
       "   's11': {'s20': 2},\n",
       "   's12': {'s20': 1},\n",
       "   's14': {'s20': 2},\n",
       "   's15': {'s1': 1},\n",
       "   's17': {'s20': 2},\n",
       "   's18': {'s20': 6},\n",
       "   's26': {'s1': 1},\n",
       "   's29': {'s20': 1},\n",
       "   's3': {'s20': 1},\n",
       "   's38': {'s20': 1},\n",
       "   's4': {'s20': 2},\n",
       "   's40': {'s20': 2, 's1': 2},\n",
       "   's5': {'s1': 2},\n",
       "   's9': {'s1': 6, 's20': 1}},\n",
       "  'min_probabs': 0.5},\n",
       " 'svm_lda': {'not_reco_imgs': {}, 'mis_classes': {}, 'min_probabs': 0.5},\n",
       " 'svm_pca_lda': {'not_reco_imgs': {},\n",
       "  'mis_classes': {'s10': {'s30': 3}, 's36': {'s2': 1}, 's6': {'s31': 1}},\n",
       "  'min_probabs': 0.5},\n",
       " 'dnn_pca': {'not_reco_imgs': {},\n",
       "  'mis_classes': {'s36': {'s4': 1, 's5': 1},\n",
       "   's40': {'s38': 1},\n",
       "   's9': {'s12': 1}},\n",
       "  'min_probabs': 0.13521852},\n",
       " 'dnn_lda': {'not_reco_imgs': {},\n",
       "  'mis_classes': {'s26': {'s9': 1, 's28': 1}},\n",
       "  'min_probabs': 0.34001634},\n",
       " 'dnn_pca_lda': {'not_reco_imgs': {},\n",
       "  'mis_classes': {'s18': {'s40': 1}, 's26': {'s1': 1}, 's4': {'s27': 1}},\n",
       "  'min_probabs': 0.1431551}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4a3bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.pkl\",\"wb\") as f:\n",
    "    pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcaff648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassifications for svm_pca: 38\n",
      "Accuracy: 0.905 \n",
      "\n",
      "Total misclassifications for svm_lda: 0\n",
      "Accuracy: 1.0 \n",
      "\n",
      "Total misclassifications for svm_pca_lda: 5\n",
      "Accuracy: 0.9875 \n",
      "\n",
      "Total misclassifications for dnn_pca: 4\n",
      "Accuracy: 0.99 \n",
      "\n",
      "Total misclassifications for dnn_lda: 2\n",
      "Accuracy: 0.995 \n",
      "\n",
      "Total misclassifications for dnn_pca_lda: 3\n",
      "Accuracy: 0.9925 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, mdict in results.items():\n",
    "    ct = 0\n",
    "    for pred in mdict['mis_classes'].values():\n",
    "        for i in pred.values():\n",
    "            ct += i\n",
    "    print(f\"Total misclassifications for {model}:\",ct\n",
    "    print(\"Accuracy:\",1-ct/400,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cea10570",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=0\n",
    "list_dir = []\n",
    "for i,a1 in enumerate(x_test):\n",
    "    for j,a2 in enumerate(embeddings_att):\n",
    "        if np.array_equal(a1, a2, equal_nan=False):\n",
    "            list_dir.append(rf\"{metadata_att[j].name}\\{metadata_att[j].file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b776f492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s11\\\\5.pgm',\n",
       " 's2\\\\4.pgm',\n",
       " 's40\\\\1.pgm',\n",
       " 's23\\\\3.pgm',\n",
       " 's29\\\\9.pgm',\n",
       " 's6\\\\5.pgm',\n",
       " 's27\\\\4.pgm',\n",
       " 's17\\\\2.pgm',\n",
       " 's21\\\\7.pgm',\n",
       " 's32\\\\4.pgm',\n",
       " 's34\\\\3.pgm',\n",
       " 's12\\\\6.pgm',\n",
       " 's27\\\\6.pgm',\n",
       " 's20\\\\9.pgm',\n",
       " 's35\\\\10.pgm',\n",
       " 's13\\\\3.pgm',\n",
       " 's33\\\\5.pgm',\n",
       " 's8\\\\10.pgm',\n",
       " 's16\\\\10.pgm',\n",
       " 's39\\\\1.pgm',\n",
       " 's22\\\\8.pgm',\n",
       " 's30\\\\3.pgm',\n",
       " 's38\\\\5.pgm',\n",
       " 's32\\\\2.pgm',\n",
       " 's9\\\\8.pgm',\n",
       " 's39\\\\10.pgm',\n",
       " 's9\\\\1.pgm',\n",
       " 's22\\\\7.pgm',\n",
       " 's9\\\\4.pgm',\n",
       " 's16\\\\4.pgm',\n",
       " 's25\\\\2.pgm',\n",
       " 's34\\\\10.pgm',\n",
       " 's20\\\\2.pgm',\n",
       " 's4\\\\7.pgm',\n",
       " 's28\\\\9.pgm',\n",
       " 's22\\\\5.pgm',\n",
       " 's24\\\\4.pgm',\n",
       " 's26\\\\3.pgm',\n",
       " 's40\\\\4.pgm',\n",
       " 's4\\\\6.pgm',\n",
       " 's37\\\\1.pgm',\n",
       " 's30\\\\6.pgm',\n",
       " 's2\\\\5.pgm',\n",
       " 's26\\\\2.pgm',\n",
       " 's19\\\\1.pgm',\n",
       " 's16\\\\6.pgm',\n",
       " 's6\\\\4.pgm',\n",
       " 's31\\\\5.pgm',\n",
       " 's3\\\\8.pgm',\n",
       " 's33\\\\3.pgm',\n",
       " 's7\\\\6.pgm',\n",
       " 's23\\\\5.pgm',\n",
       " 's37\\\\7.pgm',\n",
       " 's5\\\\6.pgm',\n",
       " 's34\\\\9.pgm',\n",
       " 's27\\\\2.pgm',\n",
       " 's25\\\\4.pgm',\n",
       " 's34\\\\8.pgm',\n",
       " 's21\\\\1.pgm',\n",
       " 's19\\\\3.pgm',\n",
       " 's19\\\\8.pgm',\n",
       " 's10\\\\7.pgm',\n",
       " 's12\\\\3.pgm',\n",
       " 's38\\\\2.pgm',\n",
       " 's5\\\\5.pgm',\n",
       " 's7\\\\9.pgm',\n",
       " 's19\\\\7.pgm',\n",
       " 's16\\\\9.pgm',\n",
       " 's31\\\\1.pgm',\n",
       " 's24\\\\3.pgm',\n",
       " 's23\\\\2.pgm',\n",
       " 's25\\\\1.pgm',\n",
       " 's24\\\\8.pgm',\n",
       " 's5\\\\3.pgm',\n",
       " 's38\\\\9.pgm',\n",
       " 's28\\\\8.pgm',\n",
       " 's2\\\\1.pgm',\n",
       " 's38\\\\8.pgm',\n",
       " 's10\\\\3.pgm',\n",
       " 's1\\\\10.pgm',\n",
       " 's7\\\\2.pgm',\n",
       " 's17\\\\4.pgm',\n",
       " 's36\\\\3.pgm',\n",
       " 's31\\\\6.pgm',\n",
       " 's12\\\\4.pgm',\n",
       " 's13\\\\7.pgm',\n",
       " 's31\\\\10.pgm',\n",
       " 's1\\\\6.pgm',\n",
       " 's1\\\\4.pgm',\n",
       " 's4\\\\9.pgm',\n",
       " 's11\\\\6.pgm',\n",
       " 's6\\\\2.pgm',\n",
       " 's17\\\\5.pgm',\n",
       " 's8\\\\8.pgm',\n",
       " 's29\\\\3.pgm',\n",
       " 's36\\\\9.pgm',\n",
       " 's18\\\\4.pgm',\n",
       " 's26\\\\7.pgm',\n",
       " 's3\\\\9.pgm',\n",
       " 's21\\\\2.pgm',\n",
       " 's35\\\\3.pgm',\n",
       " 's27\\\\10.pgm',\n",
       " 's18\\\\2.pgm',\n",
       " 's28\\\\3.pgm',\n",
       " 's40\\\\10.pgm',\n",
       " 's20\\\\5.pgm',\n",
       " 's40\\\\7.pgm',\n",
       " 's18\\\\1.pgm',\n",
       " 's24\\\\2.pgm',\n",
       " 's33\\\\7.pgm',\n",
       " 's28\\\\4.pgm',\n",
       " 's15\\\\9.pgm',\n",
       " 's13\\\\2.pgm',\n",
       " 's17\\\\3.pgm',\n",
       " 's30\\\\5.pgm',\n",
       " 's4\\\\8.pgm',\n",
       " 's32\\\\8.pgm',\n",
       " 's23\\\\6.pgm',\n",
       " 's26\\\\8.pgm',\n",
       " 's39\\\\3.pgm',\n",
       " 's11\\\\3.pgm',\n",
       " 's2\\\\3.pgm',\n",
       " 's5\\\\8.pgm',\n",
       " 's7\\\\5.pgm',\n",
       " 's29\\\\10.pgm',\n",
       " 's14\\\\3.pgm',\n",
       " 's33\\\\4.pgm',\n",
       " 's30\\\\10.pgm',\n",
       " 's3\\\\6.pgm',\n",
       " 's10\\\\5.pgm',\n",
       " 's15\\\\2.pgm',\n",
       " 's18\\\\8.pgm',\n",
       " 's39\\\\9.pgm',\n",
       " 's14\\\\10.pgm',\n",
       " 's9\\\\5.pgm',\n",
       " 's35\\\\4.pgm',\n",
       " 's12\\\\8.pgm',\n",
       " 's8\\\\9.pgm',\n",
       " 's15\\\\10.pgm',\n",
       " 's36\\\\7.pgm',\n",
       " 's8\\\\4.pgm',\n",
       " 's22\\\\6.pgm',\n",
       " 's29\\\\6.pgm',\n",
       " 's3\\\\10.pgm',\n",
       " 's10\\\\10.pgm',\n",
       " 's6\\\\10.pgm',\n",
       " 's32\\\\1.pgm',\n",
       " 's37\\\\9.pgm',\n",
       " 's36\\\\2.pgm',\n",
       " 's35\\\\1.pgm',\n",
       " 's20\\\\3.pgm',\n",
       " 's13\\\\1.pgm',\n",
       " 's15\\\\5.pgm',\n",
       " 's21\\\\9.pgm',\n",
       " 's25\\\\9.pgm',\n",
       " 's14\\\\7.pgm',\n",
       " 's14\\\\2.pgm',\n",
       " 's37\\\\6.pgm',\n",
       " 's11\\\\1.pgm',\n",
       " 's1\\\\5.pgm']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71b35719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s2'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8980e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn pca \n",
      "\n",
      "Progress: 160 \n",
      "\n",
      "Not recognized images count:\n",
      "{} \n",
      "\n",
      "Misclassified images count:\n",
      "{'s36': {'s5': 1}, 's40': {'s38': 1}} \n",
      "\n",
      "Most minimum probability for correct classification 0.40096223\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\Users\\DELL\\Desktop\\Major Project\\AT&T Face Rec\\at&t_dataset\"\n",
    "not_reco_img = {}\n",
    "mis_class = {}\n",
    "ct = 0\n",
    "min_probab = 1\n",
    "for i in list_dir:\n",
    "    true = i.split(\"\\\\\")[0]\n",
    "    f = i.split(\"\\\\\")[1]\n",
    "    path_1 = os.path.join(path, i)\n",
    "    name, max_probab = identify(path_1, model_pca, 'dnn', 'pca')\n",
    "    if max_probab < min_probab:\n",
    "        min_probab = max_probab\n",
    "    ct += 1\n",
    "    if name == \"not recognized\":\n",
    "        if true in not_reco_img.keys():\n",
    "            not_reco_img[true].append(f)\n",
    "        else:\n",
    "            not_reco_img[true] = [f]\n",
    "    elif name != true:\n",
    "        if true in mis_class.keys():\n",
    "            if name in mis_class[true].keys():\n",
    "                mis_class[true][name] += 1\n",
    "            else:\n",
    "                mis_class[true][name] = 1\n",
    "        else:\n",
    "            mis_class[true] = {}\n",
    "            mis_class[true][name] = 1\n",
    "    else:\n",
    "        clear_output(wait=True)\n",
    "        print('dnn','pca',\"\\n\")\n",
    "        print(\"Progress:\",ct,\"\\n\")\n",
    "        print(\"Not recognized images count:\")\n",
    "        print(not_reco_img,\"\\n\")\n",
    "        print(\"Misclassified images count:\")\n",
    "        print(mis_class,\"\\n\")\n",
    "        print(\"Most minimum probability for correct classification\",min_probab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d0b4a910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassifications for dnn_pca: 2\n",
      "Accuracy: 98.75 %\n"
     ]
    }
   ],
   "source": [
    "total_misclassifications = 0\n",
    "for val in mis_class.values():\n",
    "    for i in val.values():\n",
    "        total_misclassifications += i\n",
    "print(\"Total misclassifications for dnn_pca:\", total_misclassifications)\n",
    "print(\"Accuracy:\",(1-total_misclassifications/160)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93fa00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
